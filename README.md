# AdaBoost_NN

Building Boosted ensemble with shallow neural network

The main idea of this simple repository is to build an ensemble of the Multi-layer perceptrons (classifier and regressor) with the AdaBoost boosting approach.

## MLP

Includes the neural networks with the weighting method, which samples the instances with the bagging approach and lets the AdaBoost assign weight to each instance.

## AdaBoost

As the [example](https://github.com/samanemami/AdaBoost_NN/blob/main/test/tes.py) shows, you only have to consider the Neural Network from the MLP as the base estimator and it will do the math.

### Version

0.0.1

### Released date

10.Oct.2022
